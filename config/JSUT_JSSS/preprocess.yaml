dataset: "JSUT_JSSS"

path:
  source_raw_path: "./raw_data/JSUT_JSSS/JSSS"
  source_prevoice_path: "./pre_voice/JSUT_JSSS_3/JSSS"
  target_raw_path: "./raw_data/JSUT_JSSS/JSUT"
  target_prevoice_path: "./pre_voice/JSUT_JSSS_3/JSUT"
  preprocessed_path: "./preprocessed_data/JSSS_2_JSUT"  # out_dir. こっちはsource, targetで自動で分ける.

preprocessing:
  val_size: 229 # 元は512  # 全データが3229個.
  audio:
    sampling_rate: 24000
    max_wav_value: 32768.0  # 16bitだと, -32768.0 ~ 32767.0 こうなる.
    min_silence_len: 50
    silence_thresh: -40
    keep_silence: 10
    head_tail_only: True
  stft:  # NARS2Sのpaperの値.
    filter_length: 2048  # number of FFT components
    hop_length: 300
    win_length: 1200
  mel:
    n_mel_channels: 80
    mel_fmin: 0
    mel_fmax: null # please set to 8000 for HiFi-GAN vocoder, set to null for MelGAN vocoder
                   # hifi-ganも, 1からtrainingするので, nullに設定してヨシ. nullとすれば, librosa.filters.melにおいて, 
                   # sampling_rate/2 をf_maxとしてmelを計算してくれる. そうじゃないとsr=24,000でやってる意味ない.
